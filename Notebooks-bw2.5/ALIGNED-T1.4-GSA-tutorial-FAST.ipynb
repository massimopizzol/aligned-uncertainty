{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "85f05f60-698d-441a-86a6-c68bd154daa9",
   "metadata": {},
   "source": [
    "# ALIGNED project: FAST GSA tutorial\n",
    "\n",
    "**Aligning Life Cycle Assessment methods and bio-based sectors for improved environmental performance**\n",
    "\n",
    "[http://www.alignedproject.eu/](http://www.alignedproject.eu/)\n",
    "\n",
    "_Horizon Europe grant agreement N° 101059430. Views and opinions expressed are however those of the author(s) only and do not necessarily reflect those of the European Union or the European Research Executive Agency._ \n",
    "\n",
    "\n",
    "## WP1 Shared modelling framework and learnings\n",
    "### Task 1.4 Framework for interpreting uncertainty\n",
    "\n",
    "#### Deliverable 1.2 Description of scientific methods\n",
    "\n",
    "#### Tutorial for performing Global Sensitivity Analysis using the FAST method\n",
    "\n",
    "Massimo Pizzol, Aalborg University (AAU), 2025  \n",
    "Ning An, Aalborg University (AAU), 2025\n",
    "\n",
    "This notebook show how to perform a simple Global Sensitivity Analysis (GSA) applying the FAST, a variance-based sensitivity analysis method, for an example product system of a biobased product.\n",
    "\n",
    "Credits: special thanks to [Pierre Jouannais](https://www.linkedin.com/in/pierre-jouannais-27736023b/) for preparing an early version of this tutorial.\n",
    "\n",
    "_Technical note: the SALib library is needed for this tutorial._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51eb71a0-1d53-4cf9-93fc-527297c3d5b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing packages\n",
    "import bw2data as bd\n",
    "import bw2calc as bc\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from lci_to_bw2 import * # import all the functions of this module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c352ab8e-5b07-4189-92be-3a89bb8c671b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# open a project with ecoinvent v.3.11 consequential system model\n",
    "bd.projects.set_current('advlca25')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c954bdc8-7375-48c4-b065-bd8bf3f19c30",
   "metadata": {},
   "source": [
    "We start by importing data about a fictional (\"dummy\") product system for a biobased product."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2683e606-47d3-42c9-824f-359aa1bc6291",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the dummy product system\n",
    "\n",
    "# import data from csv\n",
    "\n",
    "#mydata = pd.read_csv('LCI1-bw-format.csv', header = 0, sep = \",\") # using csv file avoids encoding problem\n",
    "mydata = pd.read_csv('ALIGNED-LCI-biobased-product-dummy.csv', header = 0, sep = \",\") # using csv file avoids encoding problem\n",
    "mydata.head()\n",
    "\n",
    "# keep only the columns not needed\n",
    "mydb = mydata[['Activity database','Activity code','Activity name','Activity unit','Activity type',\n",
    "               'Exchange database','Exchange input','Exchange amount','Exchange unit','Exchange type',\n",
    "               'Exchange uncertainty type','Exchange loc','Exchange scale','Exchange negative', \n",
    "               'Simapro name',\t'Simapro unit', 'Simapro type']].copy()\n",
    "\n",
    "mydb = mydata.copy()\n",
    "\n",
    "mydb['Exchange uncertainty type'] = mydb['Exchange uncertainty type'].fillna(0).astype(int) # uncertainty as integers\n",
    "# Note: to avoid having both nan and values in the uncertainty column I use zero as default\n",
    "\n",
    "#print(mydb.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "93a9d2cf-d78e-428b-b060-2d030650adaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m12:04:27+0200\u001b[0m [\u001b[33m\u001b[1mwarning  \u001b[0m] \u001b[1mNot able to determine geocollections for all datasets. This database is not ready for regionalization.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 6173.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m12:04:27+0200\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mVacuuming database            \u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Create dictionary in bw format and write database to disk. \n",
    "# Shut down all other notebooks using the same project before doing this\n",
    "bw2_db = lci_to_bw2(mydb) # a function from the lci_to_bw2 module\n",
    "\n",
    "# write database\n",
    "bd.Database('ALIGNED-biob-prod-dummy').write(bw2_db)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80a68d40-67ae-40f2-873d-7d0fe6a98efa",
   "metadata": {},
   "source": [
    "The product system includes different activities such as the production, use, and end of life of the biobased product."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5a1f1132-ee27-4d2e-8e52-96751037b1c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Biobased-product-use' (year, None, None) f9eabf64-b899-40c0-9f9f-2009dbb0a0b2\n",
      "'Biomass-growth' (kilogram, None, None) a7d34649-9c10-4423-bac3-ecab9b43b20c\n",
      "'Biomass-processing' (kilogram, None, None) 403a5c32-c769-46fc-8b9a-74b8eb3c79d1\n",
      "'Biobased-product-manufacturing' (kilogram, None, None) a37d149a-6508-4563-8af6-e5a39b4176df\n",
      "'Biobased-product-eol' (kilogram, None, None) c8301e73-d521-4a89-998b-30b7e7751011\n"
     ]
    }
   ],
   "source": [
    "# check what foreground activities are included\n",
    "for act in bd.Database('ALIGNED-biob-prod-dummy'):\n",
    "    print(act, act['code'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "87d2fbc6-0c31-4e91-ba67-c03aa2d9bc87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'Biobased-product-use',\n",
       " 'unit': 'year',\n",
       " 'type': 'processwithreferenceproduct',\n",
       " 'database': 'ALIGNED-biob-prod-dummy',\n",
       " 'code': 'f9eabf64-b899-40c0-9f9f-2009dbb0a0b2',\n",
       " 'id': 228456472572211203}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# More info \n",
    "myact = bd.Database('ALIGNED-biob-prod-dummy').get('f9eabf64-b899-40c0-9f9f-2009dbb0a0b2') # Biobased-product-use\n",
    "myact._data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dd2369a1-651d-4a87-8035-e0577f2b484f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': ('ALIGNED-biob-prod-dummy', 'a37d149a-6508-4563-8af6-e5a39b4176df'),\n",
       " 'amount': 50.0,\n",
       " 'unit': 'kilogram',\n",
       " 'type': 'technosphere',\n",
       " 'uncertainty type': 4,\n",
       " 'minimum': 37.5,\n",
       " 'maximum': 62.5,\n",
       " 'Notes': 'Input of manufacturing',\n",
       " 'Simapro name': 'Biobased-product-manufacturing',\n",
       " 'Simapro unit': 'kg',\n",
       " 'output': ('ALIGNED-biob-prod-dummy', 'f9eabf64-b899-40c0-9f9f-2009dbb0a0b2')}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Uncertainty is also there\n",
    "list(myact.exchanges())[1]._data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef9bff48-786d-4d2e-8ab5-39432ba6ba77",
   "metadata": {},
   "source": [
    "We calculate a static climate impact score for the fictional biobased product, to be used for reference later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bac2b163-a2b1-44d4-a56f-ec7549c2bbe4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180.28497364203196\n"
     ]
    }
   ],
   "source": [
    "# calculation of static LCA score\n",
    "mymethod = ('ecoinvent-3.11', 'IPCC 2021', 'climate change: fossil', 'global warming potential (GWP100)')\n",
    "myact = bd.Database('ALIGNED-biob-prod-dummy').get('f9eabf64-b899-40c0-9f9f-2009dbb0a0b2') # Biobased-product-use\n",
    "functional_unit = {myact: 1}\n",
    "LCA = bc.LCA(functional_unit, mymethod)\n",
    "LCA.lci()\n",
    "LCA.lcia()\n",
    "print(LCA.score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d789014d-525b-4bab-a4d7-966c3452177f",
   "metadata": {},
   "source": [
    "### Now perform sensitivity analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c9c0495-2f04-48a3-924f-8538332a78f5",
   "metadata": {},
   "source": [
    "The procedure is in three steps.\n",
    "\n",
    "1) A set of model input parameters is chosen. These are **values of specific exchanges**. A sample of values is produced for each model input **using a specific and efficient sampling design** (the **\"problem\"** below)\n",
    "2) A simulation is performed. Initial prameter values are substituted with those in the sample, iteratively, and new model outputs, that are LCA scores, are calculated.\n",
    "3) **A sensitivity index is calculated** using model input values (the \"problem\") and output values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb245484-a9af-4321-90ac-01de584a615f",
   "metadata": {},
   "source": [
    "#### Step 1\n",
    "Obtain a sample of values for each parameter.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31c97f24",
   "metadata": {},
   "source": [
    "This is a  pseudo-random sample obtained using a sampling method from the SALib package on the problem previously defined.\n",
    "\n",
    "it is defined as a __FAST__ sample (\"Fourier Amplitude Sensitivity Analysis\"), another alternative to Sobol method.\n",
    "\n",
    "Sobol and FAST sampling methods use different pseudo-random patterns to cover the space of parameters, and different calculations for the sensitivity indices.\n",
    "\n",
    "Besides these differences, the (extended) FAST method is, just like the Sobol one, a variance-based method for sensitivity analysis. It provides the same information as the Sobol method but with higher computational efficiency.\n",
    "\n",
    "For further information and comparison see: \n",
    "\n",
    "_Saltelli, A.; Tarantola, S.; Chan, K. P. S. A Quantitative Model-Independent Method for Global Sensitivity Analysis of Model Output. Technometrics 1999, 41 (1), 39–56._ https://doi.org/10.1080/00401706.1999.10485594.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f2ebb7ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to import the SALib library and relaive methods for sensitvity analysis\n",
    "# do 'pip install SALib' in the brightway environment\n",
    "\n",
    "from SALib.sample import saltelli\n",
    "from SALib.sample import fast_sampler\n",
    "from SALib.analyze import sobol\n",
    "from SALib.analyze import fast\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c836c44f",
   "metadata": {},
   "source": [
    "Define the \"problem\" for the GSA analysis as indicated in the SALib library.\n",
    "Uniform distributions for the uncertainty of for each input parameter are here assumed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eb5f7aa7-699a-47a1-93e9-1170a21046f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "problem = { 'num_vars': 4, # number of variables\n",
    "            'names': ['par1', 'par2', 'par3', 'par4'], # names of variables, same as parameters\n",
    "            'bounds': [[-1.25, -0.75], # careful here to what is the lower bound with negative values...\n",
    "                       [0.1, 0.9],  \n",
    "                       [20, 60],\n",
    "                       [0.75, 1.25]] ,\n",
    "           'dists':[\"unif\",\"unif\",\"unif\",\"unif\"] } # all uniform distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ee162160",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(800, 4)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-0.95251116,  0.57598214, 43.7991072 ,  1.04748884],\n",
       "       [-0.83251116,  0.58398214, 44.5991072 ,  1.06248884],\n",
       "       [-0.78748884,  0.59198214, 45.3991072 ,  1.07748884],\n",
       "       ...,\n",
       "       [-1.10541864,  0.30733018, 29.16650907,  0.95041864],\n",
       "       [-1.10041864,  0.32333018, 30.36650907,  0.83041864],\n",
       "       [-1.09541864,  0.33933018, 31.56650907,  0.78958136]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# FAST sampler creates N*P parameters sets with N=sample size, P = number of parameters\n",
    "param_values_FAST = fast_sampler.sample(problem, 200)\n",
    "print(param_values_FAST.shape)\n",
    "\n",
    "param_values_FAST"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "027492d8-294a-43ec-9472-b3f0ce1c8406",
   "metadata": {},
   "source": [
    "Associate the values to specific exchanges using the coordinates (column and row) of the technosphere (A) and biosphere (B) matrices, taking the data directly from the BW database that we just created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "797c2652-0f85-4ceb-bf34-c39073dfa583",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In biomass growth, value of CO2 uptake\n",
    "par1 = list(bd.Database('ALIGNED-biob-prod-dummy').get('a7d34649-9c10-4423-bac3-ecab9b43b20c').exchanges())[3]\n",
    "# In biomass processing, amount of energy used.\n",
    "par2 = list(bd.Database('ALIGNED-biob-prod-dummy').get('403a5c32-c769-46fc-8b9a-74b8eb3c79d1').exchanges())[1]\n",
    "# In use of product, amount of manufactured product needed\n",
    "par3 = list(bd.Database('ALIGNED-biob-prod-dummy').get('f9eabf64-b899-40c0-9f9f-2009dbb0a0b2').exchanges())[1]\n",
    "# In use of product, amount of manufactured product needed\n",
    "par4 = list(bd.Database('ALIGNED-biob-prod-dummy').get('c8301e73-d521-4a89-998b-30b7e7751011').exchanges())[2]\n",
    "\n",
    "n_iter = len(param_values_FAST)\n",
    "param_samples = [(par1['output'],par1['input'], [i[0] for i in param_values_FAST]),\n",
    "                 (par2['output'],par2['input'], [i[1] for i in param_values_FAST]),\n",
    "                 (par3['output'],par3['input'], [i[2] for i in param_values_FAST]),\n",
    "                 (par4['output'],par4['input'], [i[3] for i in param_values_FAST])]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6d4dfdb-61dc-4dee-882c-1c8dc414b8ab",
   "metadata": {},
   "source": [
    "#### Step 2\n",
    "\n",
    "Iteration through all parameter samples. New LCA scores are calculated for each combination of values.\n",
    "\n",
    "With 800 iterations, **this will take some time**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "12c529b4-cc55-4d7a-aa96-45a5a077198d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementing the loop\n",
    "\n",
    "GSA_value_results = []\n",
    "\n",
    "\n",
    "for i in range(0,len(param_values_FAST)): \n",
    "    for s in param_samples:\n",
    "\n",
    "        # Get the 'id' using the activity object\n",
    "        col_id = bd.Database(s[0][0]).get(s[0][1]).id\n",
    "        row_id = bd.Database(s[1][0]).get(s[1][1]).id\n",
    "\n",
    "        if s[1][0] == \"ecoinvent-3.11-biosphere\":\n",
    "            col = LCA.activity_dict[col_id] # find column index of A matrix for the activity\n",
    "            row = LCA.biosphere_dict[row_id] # find row index of B matrix for the exchange\n",
    "            LCA.biosphere_matrix[row,col] = s[2][i] # substitute the value\n",
    "        \n",
    "        else:\n",
    "            col = LCA.activity_dict[col_id] # find column index of A matrix for the activity\n",
    "            row = LCA.activity_dict[row_id] # find row index of B matrix for the exchange\n",
    "            LCA.technosphere_matrix[row,col] = -s[2][i] # substitute the value\n",
    "        \n",
    "    LCA.redo_lci() # uses the new A matrix\n",
    "    LCA.lcia()\n",
    "    #print(LCA.score)\n",
    "    GSA_value_results.append(LCA.score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53eb6494-b3ad-42fa-8bd0-f96d344461ea",
   "metadata": {},
   "source": [
    "#### Step 3\n",
    "\n",
    "Now we have both the input and output values and we can feed the problem and the results to the Sobol function to obtain the FAST indices.\n",
    "\n",
    "First we look at the parameters and the result\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "34eb51f9-baf0-414a-aa29-ce672d3c69ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>par0</th>\n",
       "      <th>par1</th>\n",
       "      <th>par2</th>\n",
       "      <th>par3</th>\n",
       "      <th>GWI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.952511</td>\n",
       "      <td>0.575982</td>\n",
       "      <td>43.799107</td>\n",
       "      <td>1.047489</td>\n",
       "      <td>167.723874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.832511</td>\n",
       "      <td>0.583982</td>\n",
       "      <td>44.599107</td>\n",
       "      <td>1.062489</td>\n",
       "      <td>173.245951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.787489</td>\n",
       "      <td>0.591982</td>\n",
       "      <td>45.399107</td>\n",
       "      <td>1.077489</td>\n",
       "      <td>177.162311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.907489</td>\n",
       "      <td>0.599982</td>\n",
       "      <td>46.199107</td>\n",
       "      <td>1.092489</td>\n",
       "      <td>177.302990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.027489</td>\n",
       "      <td>0.607982</td>\n",
       "      <td>46.999107</td>\n",
       "      <td>1.107489</td>\n",
       "      <td>177.347911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-1.147489</td>\n",
       "      <td>0.615982</td>\n",
       "      <td>47.799107</td>\n",
       "      <td>1.122489</td>\n",
       "      <td>177.297076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-1.232511</td>\n",
       "      <td>0.623982</td>\n",
       "      <td>48.599107</td>\n",
       "      <td>1.137489</td>\n",
       "      <td>178.000426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-1.112511</td>\n",
       "      <td>0.631982</td>\n",
       "      <td>49.399107</td>\n",
       "      <td>1.152489</td>\n",
       "      <td>183.699960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-0.992511</td>\n",
       "      <td>0.639982</td>\n",
       "      <td>50.199107</td>\n",
       "      <td>1.167489</td>\n",
       "      <td>189.495738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-0.872511</td>\n",
       "      <td>0.647982</td>\n",
       "      <td>50.999107</td>\n",
       "      <td>1.182489</td>\n",
       "      <td>195.387758</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       par0      par1       par2      par3         GWI\n",
       "0 -0.952511  0.575982  43.799107  1.047489  167.723874\n",
       "1 -0.832511  0.583982  44.599107  1.062489  173.245951\n",
       "2 -0.787489  0.591982  45.399107  1.077489  177.162311\n",
       "3 -0.907489  0.599982  46.199107  1.092489  177.302990\n",
       "4 -1.027489  0.607982  46.999107  1.107489  177.347911\n",
       "5 -1.147489  0.615982  47.799107  1.122489  177.297076\n",
       "6 -1.232511  0.623982  48.599107  1.137489  178.000426\n",
       "7 -1.112511  0.631982  49.399107  1.152489  183.699960\n",
       "8 -0.992511  0.639982  50.199107  1.167489  189.495738\n",
       "9 -0.872511  0.647982  50.999107  1.182489  195.387758"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Organize data first to give a look at what we have done: a sample of input values and a corresponding output value\n",
    "fast_data = pd.DataFrame([i[2] for i in param_samples], index = ['par0','par1', 'par2', 'par3']).T\n",
    "fast_data['GWI'] = GSA_value_results\n",
    "fast_data.head(10) # show only the first ten samples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34374d03-0e63-4743-b692-971e178b6bd1",
   "metadata": {},
   "source": [
    "Now we calculate the SI index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a4d910f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            S1        ST   S1_conf   ST_conf\n",
      "par1  0.008731  0.010354  0.069247  0.091341\n",
      "par2  0.000032  0.000809  0.066464  0.088662\n",
      "par3  0.934124  0.937016  0.062582  0.097299\n",
      "par4  0.055131  0.057432  0.084735  0.089503\n"
     ]
    }
   ],
   "source": [
    "si = fast.analyze(problem, np.array(GSA_value_results), print_to_console=True) # must use np.array"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0023c8f-8205-4c4b-a2d3-24cca5ff1c8a",
   "metadata": {},
   "source": [
    "In this specific case \"par3\"  is the parameter to which the results are most sensitive to, this because it has the highest value for \"S1\" which is the first order effect.\n",
    "\n",
    "This is determined with relatively good confidence as the error (value of \"S1_conf\") is small compared to the coefficient.\n",
    "\n",
    "Note also that \"par3\" is also the parameter with highest sensitivity in the total model, i.e. when in combinatino with other parameters, as observed by the highest value of \"ST\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b1937deb-8701-42ad-a38c-740e47856865",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Exchange: 50.0 kilogram 'Biobased-product-manufacturing' (kilogram, None, None) to 'Biobased-product-use' (year, None, None)>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# In this specific case \"par3\" is the parameter to which the results ar emost sensitive to, and values have high confidente (small error)\n",
    "# what was \"par3\" again?\n",
    "par3 # amount of manufactured product need din the use stage"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
